{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import calendar\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from matplotlib.collections import PatchCollection\n",
    "import hashlib\n",
    "from time import sleep\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from data import read_history\n",
    "from functools import lru_cache\n",
    "from matplotlib.patches import Rectangle\n",
    "import squarify\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage,\n",
    "                                  AnnotationBbox)\n",
    "import os\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "kg_caches = Path(\"kgcaches\")\n",
    "kg_caches.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $kg_caches.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_history = read_history()\n",
    "print(len(streaming_history))\n",
    "streaming_history.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(streaming_history[\"artistName\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Google KnowledgeGraph API\n",
    "\n",
    "Remember to activate your api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_kg(artist_name):\n",
    "    hash_object = hashlib.md5(artist_name.encode('utf-8'))\n",
    "    file = kg_caches / f\"{hash_object.hexdigest()}.json\"\n",
    "    if file.exists():\n",
    "        with open(file) as readable:\n",
    "            return json.load(readable)\n",
    "    \n",
    "    service_url = 'https://kgsearch.googleapis.com/v1/entities:search'\n",
    "    params = {\n",
    "        'query': artist_name,\n",
    "        'limit': 30,\n",
    "        'indent': True,\n",
    "        'key': os.environ[\"GOOGLE_KG_API_KEY\"],\n",
    "    }\n",
    "    response = requests.get(service_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    document = json.loads(response.text)\n",
    "\n",
    "    with open(file, \"w\") as writable:\n",
    "        json.dump(document, writable, indent=4)\n",
    "    \n",
    "    sleep(0.5)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "artists_info = dict()\n",
    "for i, artist in enumerate(streaming_history[\"artistName\"].unique()):\n",
    "    if i % 300 == 0:\n",
    "        print(i, artist)\n",
    "    artists_info[artist] = query_kg(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def flatten(d, parent_key='', sep='.'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "        \n",
    "allowed_types = set([\"MusicGroup\", \"Person\"])\n",
    "artistNames = []\n",
    "results = []\n",
    "for artist, info in artists_info.items():\n",
    "    item_list = info[\"itemListElement\"]\n",
    "    for result in (item[\"result\"] for item in item_list if \"result\" in item):\n",
    "        types = set(result.get(\"@type\",[]))\n",
    "        if types & allowed_types:\n",
    "            results.append(flatten(result))\n",
    "            artistNames.append(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = pd.DataFrame(results)\n",
    "details[\"artistName\"] = artistNames\n",
    "details = details[~details[\"detailedDescription.articleBody\"].isna()].reset_index(drop=True)\n",
    "print(len(details))\n",
    "details.sample(5, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = set([\"GPE\", \"NORP\", \"LANGUAGE\", \"LOC\"])\n",
    "with open(\"nationalities.csv\") as readable:\n",
    "    nationalities = set([nat.strip().lower() for nat in readable])\n",
    "\n",
    "def extract_nationality(description):\n",
    "    # This one could obviously be improved!\n",
    "    doc = nlp(description)\n",
    "    for ent in filter(\n",
    "        lambda entity: (entity.label_ in labels) and (entity.text.lower() in nationalities), \n",
    "        doc.ents):\n",
    "        return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_nationality = {}\n",
    "for _, row in details.iterrows():\n",
    "    artistName = row[\"artistName\"]\n",
    "    if artist_nationality.get(artistName):\n",
    "        continue\n",
    "    artist_nationality[artistName] = extract_nationality(row[\"detailedDescription.articleBody\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_nationality[\"Red Hot Chili Peppers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "streaming_history[\"nationality\"] = streaming_history[\"artistName\"].apply(lambda artist: artist_nationality.get(artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contry_counts = streaming_history[~streaming_history[\"artistName\"].duplicated()].groupby(\"nationality\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_X = contry_counts.sort_values(by=\"msPlayed\").tail(10)\n",
    "top_X.sort_values(by=\"artistName\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationality_artist_text = {\n",
    "    nationality: \" \".join(streaming_history.query(f\"nationality == '{nationality}'\")[\"artistName\"].values) \n",
    "    for nationality in top_X[\"artistName\"].index\n",
    "}\n",
    "\n",
    "nationality_artist_text[\"British\"][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities_colors = {\n",
    "    \"Japanese\": \"Reds\",\n",
    "    \"English\": \"Oranges\",\n",
    "    \"American\": \"Blues\",\n",
    "    \"Mexican\": \"Greens\",\n",
    "    \"British\": \"RdPu\",\n",
    "    \"Australian\": \"PuBu\",\n",
    "    \"Canadian\": \"Purples\",\n",
    "    \"German\": \"GnBu\",\n",
    "    \"French\": \"OrRd\",\n",
    "    \"Spanish\": \"YlOrBr\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 2000, 2000\n",
    "#width, height = 500, 500\n",
    "values = squarify.normalize_sizes(top_X[\"artistName\"], width, height)\n",
    "rects = squarify.squarify(values, 0., 0., width, height)\n",
    "word_clouds = [\n",
    "    WordCloud(\n",
    "        width=int(rect[\"dx\"]),\n",
    "        height=int(rect[\"dy\"]),\n",
    "        max_font_size=50,\n",
    "        max_words=600,\n",
    "        repeat=True,\n",
    "        colormap=nationalities_colors[nationality],\n",
    "        background_color=\"rgba(0, 0, 0, 0)\"\n",
    "    ).generate(nationality_artist_text[nationality]).to_array()\n",
    "    for nationality, rect in zip(top_X[\"artistName\"].index, rects)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "offset = 50\n",
    "full_image = np.zeros((height + 2 * offset, width + 2 * offset, 3))\n",
    "\n",
    "for wc, rect in zip(word_clouds, rects):\n",
    "    x, y = int(rect[\"x\"]) + offset, int(rect[\"y\"]) + offset\n",
    "    dx, dy = int(rect[\"dx\"]), int(rect[\"dy\"])\n",
    "    full_image[y:y+dy,x:x+dx,:] = wc\n",
    "\n",
    "    \n",
    "fig = plt.figure(figsize=(50,50))\n",
    "ax = plt.subplot()\n",
    "ax.imshow(full_image/255)\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"words.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
